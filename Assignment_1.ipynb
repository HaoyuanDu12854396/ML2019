{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment 1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HaoyuanDu12854396/ML2019/blob/master/Assignment_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i7LHdBqkuTMr",
        "colab_type": "text"
      },
      "source": [
        "#Assignment 1: Report about [SHA48] INFORMATION THEORY"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Dfd9DkXyvP-T"
      },
      "source": [
        "##Introduction\n",
        "I choose the [SHA48] INFORMATION THEORY as my paper, because I want to know more things about information theory SHA48 was *A Mathematical Theory of Communication written* on *Ball System Technical Journal*, which is written by Claude Elwood Shannon in 1948. Shannonâ€™s article laid the foundation for information theory, so he was called the \"father of information theory\".For half a century, information theory has been continuously improved, enriched and developed. Until today, shannon information theory has not only played a guiding role in the field of information engineering, but also found applications in other fields, such as statistical inference, computer science and the like.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZAT0lHdqvUAt",
        "colab_type": "text"
      },
      "source": [
        "#Content\n",
        "In this report, he first proposed a method for achieving reliable communication in an interfered channel, and pointing out that the method for achieving efficient and reliable information transmission is coding.\n",
        "\n",
        "He also proposed a unit for measuring information - bit. In his view, information, like physical properties of length and weight, is something that can be measured and regulated. For information systems, the information it conveys is random, so quantitative description information should be based on random events. He also mentioned that any information is redundant, and the size of the redundancy is related to the probability or uncertainty of the occurrence of each symbol (number, letter or word) in the message. Redundancy, the size of redundancy is related to the probability or uncertainty of occurrence of each symbol (number, letter or word) in the message.\n",
        "\n",
        "At the same time, Shannon proposed using information entropy to quantitatively measure the size of information. Let us first set the uncertainty of the occurrence of random events as the function f(pi) of the probability pi. The function has the following three properties:\n",
        "\n",
        "1) Monotonicity: The event with higher probability, the smaller the information entropy, that is, pi and f(pi) are inversely proportional.\n",
        "\n",
        "2) Non-negative: f(pi) is non-negative;\n",
        "\n",
        "3) Additivity: A measure of the total uncertainty of simultaneous occurrence of multiple random events, which can be expressed as the sum of the various time uncertainty measures.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7HSha4-jvU-O",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}